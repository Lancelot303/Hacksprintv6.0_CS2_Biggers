# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pNSbmTgmvYnz9hX3VBFsyTi7-jHh8giX
"""

from google.colab import files

uploaded = files.upload()

import pandas as pd
df = pd.read_csv("global.csv")

df.head()

df.info()

# Keep only the columns we need
df = df[['url', 'category_description']]

# Rename the category column for simplicity (optional)
df = df.rename(columns={'category_description': 'category'})

# Drop rows with missing values (if any)
df = df.dropna()

# Check the cleaned data
df.head()

!pip install scikit-learn

from sklearn.feature_extraction.text import TfidfVectorizer

# Create a TF-IDF vectorizer
vectorizer = TfidfVectorizer(analyzer='char_wb', ngram_range=(3,5))

# Transform the URLs into vectors
X = vectorizer.fit_transform(df['url'])

# Labels (target)
y = df['category']

from sklearn.model_selection import train_test_split

# Split the data: 80% for training, 20% for testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression

# Initialize the model
model = LogisticRegression(max_iter=1000)

# Train it
model.fit(X_train, y_train)

from sklearn.metrics import classification_report, accuracy_score

# Predict on test set
y_pred = model.predict(X_test)

# Print evaluation metrics
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

!pip install joblib

import joblib

# Save the trained model
joblib.dump(model, "url_classifier_model.pkl")

# Save the TF-IDF vectorizer
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")

model = joblib.load("url_classifier_model.pkl")
vectorizer = joblib.load("tfidf_vectorizer.pkl")

pip install fastapi uvicorn

!pip install fastapi uvicorn nest-asyncio pyngrok

import nest_asyncio
import uvicorn

# This line allows running FastAPI in Colab
nest_asyncio.apply()

from fastapi import FastAPI
from pydantic import BaseModel
import joblib

# Load the saved model and vectorizer
model = joblib.load("url_classifier_model.pkl")
vectorizer = joblib.load("tfidf_vectorizer.pkl")

# Define the app
app = FastAPI()

# Define request body
class URLRequest(BaseModel):
    url: str

# Prediction route
@app.post("/predict")
def predict_url_category(request: URLRequest):
    url = request.url
    features = vectorizer.transform([url])
    prediction = model.predict(features)[0]
    return {"url": url, "category": prediction}

from pyngrok import ngrok

# Paste your token inside the quotes
ngrok.set_auth_token("2vXPnrCfqw0CyREIAr4c6bm7Qwl_2CKwLgEMccHvzS8oT3tvk")

public_url = ngrok.connect(8000)
print("FastAPI is live at:", public_url)

import nest_asyncio
import uvicorn

nest_asyncio.apply()

